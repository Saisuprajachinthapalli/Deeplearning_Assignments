{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_fKkYEyNRbb5",
        "outputId": "b838c7fd-1a24-4856-88fe-03bd6450b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "           0        1        2        3        4        5        6        7    \\\n",
            "count  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
            "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "\n",
            "           8        9    ...           774           775           776  \\\n",
            "count  60000.0  60000.0  ...  60000.000000  60000.000000  60000.000000   \n",
            "mean       0.0      0.0  ...      0.200433      0.088867      0.045633   \n",
            "std        0.0      0.0  ...      6.042472      3.956189      2.839845   \n",
            "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
            "\n",
            "                777           778         779      780      781      782  \\\n",
            "count  60000.000000  60000.000000  60000.0000  60000.0  60000.0  60000.0   \n",
            "mean       0.019283      0.015117      0.0020      0.0      0.0      0.0   \n",
            "std        1.686770      1.678283      0.3466      0.0      0.0      0.0   \n",
            "min        0.000000      0.000000      0.0000      0.0      0.0      0.0   \n",
            "25%        0.000000      0.000000      0.0000      0.0      0.0      0.0   \n",
            "50%        0.000000      0.000000      0.0000      0.0      0.0      0.0   \n",
            "75%        0.000000      0.000000      0.0000      0.0      0.0      0.0   \n",
            "max      253.000000    254.000000     62.0000      0.0      0.0      0.0   \n",
            "\n",
            "           783  \n",
            "count  60000.0  \n",
            "mean       0.0  \n",
            "std        0.0  \n",
            "min        0.0  \n",
            "25%        0.0  \n",
            "50%        0.0  \n",
            "75%        0.0  \n",
            "max        0.0  \n",
            "\n",
            "[8 rows x 784 columns]\n",
            "                  0\n",
            "count  60000.000000\n",
            "mean       4.453933\n",
            "std        2.889270\n",
            "min        0.000000\n",
            "25%        2.000000\n",
            "50%        4.000000\n",
            "75%        7.000000\n",
            "max        9.000000\n",
            "           0        1        2        3        4        5        6        7    \\\n",
            "count  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0   \n",
            "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
            "\n",
            "           8        9    ...           774           775           776  \\\n",
            "count  10000.0  10000.0  ...  10000.000000  10000.000000  10000.000000   \n",
            "mean       0.0      0.0  ...      0.179300      0.163600      0.052600   \n",
            "std        0.0      0.0  ...      5.674149      5.736072      2.420004   \n",
            "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
            "max        0.0      0.0  ...    253.000000    253.000000    156.000000   \n",
            "\n",
            "              777      778      779      780      781      782      783  \n",
            "count  10000.0000  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0  \n",
            "mean       0.0006      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "std        0.0600      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "min        0.0000      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "25%        0.0000      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "50%        0.0000      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "75%        0.0000      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "max        6.0000      0.0      0.0      0.0      0.0      0.0      0.0  \n",
            "\n",
            "[8 rows x 784 columns]\n",
            "                  0\n",
            "count  10000.000000\n",
            "mean       4.443400\n",
            "std        2.895865\n",
            "min        0.000000\n",
            "25%        2.000000\n",
            "50%        4.000000\n",
            "75%        7.000000\n",
            "max        9.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m615,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m7,850\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">615,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m623,290\u001b[0m (2.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">623,290</span> (2.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m623,290\u001b[0m (2.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">623,290</span> (2.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/10\n",
            "300/300 - 8s - 26ms/step - accuracy: 0.9201 - loss: 0.2806 - val_accuracy: 0.9626 - val_loss: 0.1335\n",
            "Epoch 2/10\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9679 - loss: 0.1118 - val_accuracy: 0.9679 - val_loss: 0.1069\n",
            "Epoch 3/10\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.9789 - loss: 0.0723 - val_accuracy: 0.9764 - val_loss: 0.0753\n",
            "Epoch 4/10\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.9855 - loss: 0.0510 - val_accuracy: 0.9779 - val_loss: 0.0707\n",
            "Epoch 5/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9893 - loss: 0.0371 - val_accuracy: 0.9799 - val_loss: 0.0674\n",
            "Epoch 6/10\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.9929 - loss: 0.0268 - val_accuracy: 0.9798 - val_loss: 0.0626\n",
            "Epoch 7/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9955 - loss: 0.0189 - val_accuracy: 0.9794 - val_loss: 0.0650\n",
            "Epoch 8/10\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9969 - loss: 0.0145 - val_accuracy: 0.9814 - val_loss: 0.0604\n",
            "Epoch 9/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.9972 - loss: 0.0123 - val_accuracy: 0.9792 - val_loss: 0.0654\n",
            "Epoch 10/10\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9986 - loss: 0.0084 - val_accuracy: 0.9819 - val_loss: 0.0602\n",
            "Baseline Error: 1.81%\n",
            "1st time changing batch size and epoch values\n",
            "Epoch 1/13\n",
            "600/600 - 8s - 14ms/step - accuracy: 0.9897 - loss: 0.0306 - val_accuracy: 0.9791 - val_loss: 0.0727\n",
            "Epoch 2/13\n",
            "600/600 - 8s - 14ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.9796 - val_loss: 0.0716\n",
            "Epoch 3/13\n",
            "600/600 - 9s - 15ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.9808 - val_loss: 0.0704\n",
            "Epoch 4/13\n",
            "600/600 - 8s - 13ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9800 - val_loss: 0.0780\n",
            "Epoch 5/13\n",
            "600/600 - 10s - 17ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9806 - val_loss: 0.0729\n",
            "Epoch 6/13\n",
            "600/600 - 10s - 17ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9809 - val_loss: 0.0756\n",
            "Epoch 7/13\n",
            "600/600 - 7s - 12ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.9789 - val_loss: 0.0870\n",
            "Epoch 8/13\n",
            "600/600 - 11s - 18ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9805 - val_loss: 0.0832\n",
            "Epoch 9/13\n",
            "600/600 - 11s - 18ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9816 - val_loss: 0.0791\n",
            "Epoch 10/13\n",
            "600/600 - 8s - 13ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9806 - val_loss: 0.0921\n",
            "Epoch 11/13\n",
            "600/600 - 9s - 15ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9817 - val_loss: 0.0778\n",
            "Epoch 12/13\n",
            "600/600 - 8s - 13ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9798 - val_loss: 0.0857\n",
            "Epoch 13/13\n",
            "600/600 - 10s - 17ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9804 - val_loss: 0.0963\n",
            "Baseline Error: 1.96%\n",
            "2nd time changing batch size and epoch values\n",
            "Epoch 1/11\n",
            "429/429 - 7s - 16ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9845 - val_loss: 0.0717\n",
            "Epoch 2/11\n",
            "429/429 - 6s - 13ms/step - accuracy: 1.0000 - loss: 2.5708e-04 - val_accuracy: 0.9844 - val_loss: 0.0715\n",
            "Epoch 3/11\n",
            "429/429 - 11s - 25ms/step - accuracy: 1.0000 - loss: 1.0717e-04 - val_accuracy: 0.9844 - val_loss: 0.0721\n",
            "Epoch 4/11\n",
            "429/429 - 6s - 14ms/step - accuracy: 1.0000 - loss: 8.1296e-05 - val_accuracy: 0.9848 - val_loss: 0.0728\n",
            "Epoch 5/11\n",
            "429/429 - 10s - 23ms/step - accuracy: 1.0000 - loss: 6.7044e-05 - val_accuracy: 0.9847 - val_loss: 0.0735\n",
            "Epoch 6/11\n",
            "429/429 - 7s - 16ms/step - accuracy: 1.0000 - loss: 5.5221e-05 - val_accuracy: 0.9847 - val_loss: 0.0742\n",
            "Epoch 7/11\n",
            "429/429 - 10s - 23ms/step - accuracy: 1.0000 - loss: 4.7156e-05 - val_accuracy: 0.9848 - val_loss: 0.0751\n",
            "Epoch 8/11\n",
            "429/429 - 10s - 23ms/step - accuracy: 1.0000 - loss: 4.2198e-05 - val_accuracy: 0.9851 - val_loss: 0.0757\n",
            "Epoch 9/11\n",
            "429/429 - 10s - 23ms/step - accuracy: 1.0000 - loss: 3.5074e-05 - val_accuracy: 0.9850 - val_loss: 0.0761\n",
            "Epoch 10/11\n",
            "429/429 - 10s - 24ms/step - accuracy: 1.0000 - loss: 3.1134e-05 - val_accuracy: 0.9851 - val_loss: 0.0764\n",
            "Epoch 11/11\n",
            "429/429 - 7s - 16ms/step - accuracy: 1.0000 - loss: 2.6760e-05 - val_accuracy: 0.9852 - val_loss: 0.0771\n",
            "Baseline Error: 1.48%\n",
            "3rd time changing batch size and epoch values\n",
            "Epoch 1/10\n",
            "334/334 - 5s - 15ms/step - accuracy: 1.0000 - loss: 2.1864e-05 - val_accuracy: 0.9849 - val_loss: 0.0777\n",
            "Epoch 2/10\n",
            "334/334 - 6s - 18ms/step - accuracy: 1.0000 - loss: 1.9345e-05 - val_accuracy: 0.9850 - val_loss: 0.0784\n",
            "Epoch 3/10\n",
            "334/334 - 5s - 15ms/step - accuracy: 1.0000 - loss: 1.7198e-05 - val_accuracy: 0.9846 - val_loss: 0.0792\n",
            "Epoch 4/10\n",
            "334/334 - 6s - 17ms/step - accuracy: 1.0000 - loss: 1.5327e-05 - val_accuracy: 0.9851 - val_loss: 0.0799\n",
            "Epoch 5/10\n",
            "334/334 - 5s - 15ms/step - accuracy: 1.0000 - loss: 1.3608e-05 - val_accuracy: 0.9851 - val_loss: 0.0798\n",
            "Epoch 6/10\n",
            "334/334 - 5s - 16ms/step - accuracy: 1.0000 - loss: 1.1958e-05 - val_accuracy: 0.9852 - val_loss: 0.0809\n",
            "Epoch 7/10\n",
            "334/334 - 10s - 30ms/step - accuracy: 1.0000 - loss: 1.0608e-05 - val_accuracy: 0.9850 - val_loss: 0.0813\n",
            "Epoch 8/10\n",
            "334/334 - 6s - 17ms/step - accuracy: 1.0000 - loss: 9.2433e-06 - val_accuracy: 0.9852 - val_loss: 0.0816\n",
            "Epoch 9/10\n",
            "334/334 - 10s - 31ms/step - accuracy: 1.0000 - loss: 8.0627e-06 - val_accuracy: 0.9849 - val_loss: 0.0831\n",
            "Epoch 10/10\n",
            "334/334 - 11s - 32ms/step - accuracy: 1.0000 - loss: 7.1892e-06 - val_accuracy: 0.9849 - val_loss: 0.0840\n",
            "Baseline Error: 1.51%\n",
            "4th time changing batch size and epoch values\n",
            "Epoch 1/7\n",
            "273/273 - 5s - 17ms/step - accuracy: 1.0000 - loss: 6.2185e-06 - val_accuracy: 0.9850 - val_loss: 0.0837\n",
            "Epoch 2/7\n",
            "273/273 - 6s - 21ms/step - accuracy: 1.0000 - loss: 5.7016e-06 - val_accuracy: 0.9854 - val_loss: 0.0842\n",
            "Epoch 3/7\n",
            "273/273 - 5s - 17ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9768 - val_loss: 0.1439\n",
            "Epoch 4/7\n",
            "273/273 - 5s - 18ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.9827 - val_loss: 0.0838\n",
            "Epoch 5/7\n",
            "273/273 - 6s - 22ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9826 - val_loss: 0.0875\n",
            "Epoch 6/7\n",
            "273/273 - 5s - 17ms/step - accuracy: 1.0000 - loss: 2.5633e-04 - val_accuracy: 0.9836 - val_loss: 0.0825\n",
            "Epoch 7/7\n",
            "273/273 - 6s - 22ms/step - accuracy: 1.0000 - loss: 8.2429e-05 - val_accuracy: 0.9839 - val_loss: 0.0819\n",
            "Baseline Error: 1.61%\n",
            "5th time changing batch size and epoch values\n",
            "Epoch 1/5\n",
            "240/240 - 4s - 18ms/step - accuracy: 1.0000 - loss: 6.2875e-05 - val_accuracy: 0.9838 - val_loss: 0.0830\n",
            "Epoch 2/5\n",
            "240/240 - 6s - 25ms/step - accuracy: 1.0000 - loss: 5.3461e-05 - val_accuracy: 0.9839 - val_loss: 0.0832\n",
            "Epoch 3/5\n",
            "240/240 - 9s - 39ms/step - accuracy: 1.0000 - loss: 4.6626e-05 - val_accuracy: 0.9842 - val_loss: 0.0835\n",
            "Epoch 4/5\n",
            "240/240 - 6s - 24ms/step - accuracy: 1.0000 - loss: 4.1287e-05 - val_accuracy: 0.9841 - val_loss: 0.0838\n",
            "Epoch 5/5\n",
            "240/240 - 4s - 18ms/step - accuracy: 1.0000 - loss: 3.6772e-05 - val_accuracy: 0.9841 - val_loss: 0.0842\n",
            "Baseline Error: 1.59%\n",
            "The Changes which I have observed by changing the batch size and epoch values are, By Using a larger batch size and fewer epochs can lead to faster training and may still achieve good performance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m615,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">615,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m724,826\u001b[0m (2.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">724,826</span> (2.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m724,826\u001b[0m (2.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">724,826</span> (2.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/10\n",
            "300/300 - 8s - 26ms/step - accuracy: 0.9248 - loss: 0.2600 - val_accuracy: 0.9657 - val_loss: 0.1168\n",
            "Epoch 2/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9730 - loss: 0.0885 - val_accuracy: 0.9769 - val_loss: 0.0749\n",
            "Epoch 3/10\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.9823 - loss: 0.0560 - val_accuracy: 0.9779 - val_loss: 0.0697\n",
            "Epoch 4/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9878 - loss: 0.0391 - val_accuracy: 0.9779 - val_loss: 0.0704\n",
            "Epoch 5/10\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9908 - loss: 0.0290 - val_accuracy: 0.9774 - val_loss: 0.0746\n",
            "Epoch 6/10\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.9930 - loss: 0.0212 - val_accuracy: 0.9779 - val_loss: 0.0700\n",
            "Epoch 7/10\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9944 - loss: 0.0175 - val_accuracy: 0.9810 - val_loss: 0.0702\n",
            "Epoch 8/10\n",
            "300/300 - 10s - 33ms/step - accuracy: 0.9952 - loss: 0.0149 - val_accuracy: 0.9802 - val_loss: 0.0701\n",
            "Epoch 9/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.9795 - val_loss: 0.0782\n",
            "Epoch 10/10\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9812 - val_loss: 0.0805\n",
            "Baseline Error: 1.88%\n",
            " The first hidden layer has num_pixels neurons.\n",
            "          The second hidden layer has 128 neurons.\n",
            "          The third hidden layer has 64 neurons.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train.reshape(-1, 28*28))\n",
        "Y_train_df = pd.DataFrame(Y_train)\n",
        "X_test_df = pd.DataFrame(X_test.reshape(-1, 28*28))\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "# describe (X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "print(X_train_df.describe())\n",
        "print(Y_train_df.describe())\n",
        "print(X_test_df.describe())\n",
        "print(Y_test_df.describe())\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "# one hot encode outputs\n",
        "\n",
        "Y_train = tensorflow.keras.utils.to_categorical(Y_train)\n",
        "Y_test = tensorflow.keras.utils.to_categorical(Y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "\n",
        "# define baseline model\n",
        "# create model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model_summary\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "# change epochs and batch_size later\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "\n",
        "# 2) Explain the change in performance by changing these parameters: epochs and batch_size (five times)\n",
        "\n",
        "print('1st time changing batch size and epoch values')\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=13, batch_size=100, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('2nd time changing batch size and epoch values')\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=11, batch_size=140, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('3rd time changing batch size and epoch values')\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=180, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('4th time changing batch size and epoch values')\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=7, batch_size=220, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('5th time changing batch size and epoch values')\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=250, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "print('The Changes which I have observed by changing the batch size and epoch values are, By Using a larger batch size and fewer epochs can lead to faster training and may still achieve good performance.')\n",
        "\n",
        "\n",
        "\n",
        "# 3) [4 pts] Add a few additional hidden layers in the network and explain the changes in performance.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# The first hidden layer has num_pixels neurons. The second hidden layer has 128 neurons. The third hidden layer has 64 neurons.\n",
        "\n",
        "# model_summary\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "# change epochs and batch_size later\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}