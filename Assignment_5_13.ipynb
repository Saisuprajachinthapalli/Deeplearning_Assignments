{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzZqFpwBe32X",
        "outputId": "aea36405-11f0-452c-b395-3e3f69ec6975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "Showing the shape of X_train and X_test\n",
            "(25000, 500)\n",
            "(25000, 500)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          160000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213301 (833.21 KB)\n",
            "Trainable params: 213301 (833.21 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------\n",
            "the accuracy is\n",
            "adding another LSTM layer(100)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 500, 100)          53200     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293701 (1.12 MB)\n",
            "Trainable params: 293701 (1.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------\n",
            "the accuracy is\n",
            "-----------------------------------------------------------------------\n",
            "Shape of X_train: (25000, 500)\n",
            "Shape of X_test: (25000, 500)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213301 (833.21 KB)\n",
            "Trainable params: 213301 (833.21 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------\n",
            "-----------------------------------------------------------------\n",
            "changing embedding vector dimension value to 16\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 16)          80000     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 100)               46800     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126901 (495.71 KB)\n",
            "Trainable params: 126901 (495.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "------------------------------------------------------------------\n",
            "the accuracy is\n",
            "------------------------------------------------------------------\n",
            "changing embedding vector dimension value to 64\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 64)          320000    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100)               66000     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386101 (1.47 MB)\n",
            "Trainable params: 386101 (1.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "391/391 [==============================] - 332s 842ms/step - loss: 0.4252 - accuracy: 0.7969\n",
            "------------------------------------------------------------------\n",
            "the accuracy is\n",
            "85.80800294876099\n",
            "------------------------------------------------------------------\n",
            "changing embedding vector dimension value to 8\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 8)           40000     \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 100)               43600     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83701 (326.96 KB)\n",
            "Trainable params: 83701 (326.96 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "391/391 [==============================] - 258s 653ms/step - loss: 0.4949 - accuracy: 0.7386\n",
            "------------------------------------------------------------------\n",
            "the accuracy is\n",
            "84.82800126075745\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# Show the shape of X_train and X_test\n",
        "\n",
        "print('Showing the shape of X_train and X_test')\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# create the model\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# You can change epochs\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Show the accuracy\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('the accuracy is')\n",
        "\n",
        "print(scores[1] * 100)\n",
        "\n",
        "\n",
        "# 2) add another LSTM layer(100) right after Embedding and compare the results.\n",
        "\n",
        "print('adding another LSTM layer(100)')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(LSTM(100, return_sequences=True))  # Add another LSTM layer with return_sequences=True\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('the accuracy is')\n",
        "\n",
        "print(scores[1] * 100)\n",
        "\n",
        "print('-----------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# 3) add the following.\n",
        "\n",
        "     # LSTM(100, dropout=0.3, recurrent_dropout=0.25))\n",
        "     #  model.add(Dropout(0.2))\n",
        "     #  Compare the results.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# Show the shape of X_train and X_test\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of X_test:', X_test.shape)\n",
        "\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length, input_length=max_review_length))\n",
        "\n",
        "\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.25))\n",
        "\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)  # You can change epochs as desired\n",
        "\n",
        "# Evaluate the model on test data\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print the accuracy\n",
        "print('------------------------------------------------------------------')\n",
        "print(scores[1] * 100)\n",
        "\n",
        "print('-----------------------------------------------------------------')\n",
        "\n",
        "# 4)  change embedding vector dimension three times and compare the results.\n",
        "\n",
        "print('changing embedding vector dimension value to 16')\n",
        "\n",
        "embedding_vecor_length = 16\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# You can change epochs\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Show the accuracy\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('the accuracy is')\n",
        "\n",
        "print(scores[1] * 100)\n",
        "\n",
        "\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('changing embedding vector dimension value to 64')\n",
        "\n",
        "embedding_vecor_length = 64\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# You can change epochs\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Show the accuracy\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('the accuracy is')\n",
        "\n",
        "print(scores[1] * 100)\n",
        "\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "print('changing embedding vector dimension value to 8')\n",
        "\n",
        "embedding_vecor_length = 8\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=top_words, output_dim=embedding_vecor_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# You can change epochs\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Show the accuracy\n",
        "\n",
        "print('------------------------------------------------------------------')\n",
        "\n",
        "print('the accuracy is')\n",
        "\n",
        "print(scores[1] * 100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}